{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNArc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/triloksm/deeplearning-models/blob/master/CNNArc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline model with dropout on the cifar10 dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = tensorflow.keras.utils.to_categorical(trainY)\n",
        "\ttestY = tensorflow.keras.utils.to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainY, epochs=200, batch_size=256, validation_data=(testX, testY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaojeKSiHlyZ",
        "outputId": "4d371fa3-fe81-4ff7-8f41-2ef19574a6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "196/196 [==============================] - 25s 117ms/step - loss: 2.3778 - accuracy: 0.1316 - val_loss: 2.2213 - val_accuracy: 0.1938\n",
            "Epoch 2/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 2.2001 - accuracy: 0.1760 - val_loss: 2.1339 - val_accuracy: 0.2276\n",
            "Epoch 3/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 2.1190 - accuracy: 0.2055 - val_loss: 2.0695 - val_accuracy: 0.2534\n",
            "Epoch 4/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 2.0751 - accuracy: 0.2221 - val_loss: 2.0368 - val_accuracy: 0.2656\n",
            "Epoch 5/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 2.0370 - accuracy: 0.2402 - val_loss: 2.0052 - val_accuracy: 0.2774\n",
            "Epoch 6/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 2.0081 - accuracy: 0.2549 - val_loss: 1.9674 - val_accuracy: 0.3006\n",
            "Epoch 7/200\n",
            "196/196 [==============================] - 23s 116ms/step - loss: 1.9738 - accuracy: 0.2725 - val_loss: 1.9375 - val_accuracy: 0.3162\n",
            "Epoch 8/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.9414 - accuracy: 0.2845 - val_loss: 1.8965 - val_accuracy: 0.3355\n",
            "Epoch 9/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.9057 - accuracy: 0.3039 - val_loss: 1.8523 - val_accuracy: 0.3500\n",
            "Epoch 10/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.8712 - accuracy: 0.3144 - val_loss: 1.8227 - val_accuracy: 0.3583\n",
            "Epoch 11/200\n",
            "196/196 [==============================] - 23s 116ms/step - loss: 1.8373 - accuracy: 0.3273 - val_loss: 1.7764 - val_accuracy: 0.3763\n",
            "Epoch 12/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.8111 - accuracy: 0.3361 - val_loss: 1.7741 - val_accuracy: 0.3690\n",
            "Epoch 13/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.7908 - accuracy: 0.3418 - val_loss: 1.7290 - val_accuracy: 0.3855\n",
            "Epoch 14/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.7656 - accuracy: 0.3526 - val_loss: 1.7224 - val_accuracy: 0.3730\n",
            "Epoch 15/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.7483 - accuracy: 0.3570 - val_loss: 1.6924 - val_accuracy: 0.3955\n",
            "Epoch 16/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.7329 - accuracy: 0.3610 - val_loss: 1.6763 - val_accuracy: 0.3916\n",
            "Epoch 17/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.7166 - accuracy: 0.3674 - val_loss: 1.6496 - val_accuracy: 0.4101\n",
            "Epoch 18/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.6992 - accuracy: 0.3731 - val_loss: 1.6344 - val_accuracy: 0.4143\n",
            "Epoch 19/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.6919 - accuracy: 0.3746 - val_loss: 1.6341 - val_accuracy: 0.4170\n",
            "Epoch 20/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.6793 - accuracy: 0.3814 - val_loss: 1.6156 - val_accuracy: 0.4168\n",
            "Epoch 21/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.6660 - accuracy: 0.3863 - val_loss: 1.6084 - val_accuracy: 0.4207\n",
            "Epoch 22/200\n",
            "196/196 [==============================] - 21s 110ms/step - loss: 1.6606 - accuracy: 0.3900 - val_loss: 1.6024 - val_accuracy: 0.4223\n",
            "Epoch 23/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.6498 - accuracy: 0.3899 - val_loss: 1.5743 - val_accuracy: 0.4331\n",
            "Epoch 24/200\n",
            "196/196 [==============================] - 21s 110ms/step - loss: 1.6383 - accuracy: 0.3933 - val_loss: 1.5932 - val_accuracy: 0.4270\n",
            "Epoch 25/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.6308 - accuracy: 0.4012 - val_loss: 1.5593 - val_accuracy: 0.4354\n",
            "Epoch 26/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.6188 - accuracy: 0.4032 - val_loss: 1.5503 - val_accuracy: 0.4387\n",
            "Epoch 27/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.6111 - accuracy: 0.4052 - val_loss: 1.5350 - val_accuracy: 0.4406\n",
            "Epoch 28/200\n",
            "196/196 [==============================] - 21s 110ms/step - loss: 1.6028 - accuracy: 0.4105 - val_loss: 1.5506 - val_accuracy: 0.4390\n",
            "Epoch 29/200\n",
            "196/196 [==============================] - 21s 109ms/step - loss: 1.5933 - accuracy: 0.4120 - val_loss: 1.5569 - val_accuracy: 0.4387\n",
            "Epoch 30/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5874 - accuracy: 0.4161 - val_loss: 1.5218 - val_accuracy: 0.4499\n",
            "Epoch 31/200\n",
            "196/196 [==============================] - 23s 117ms/step - loss: 1.5814 - accuracy: 0.4182 - val_loss: 1.6558 - val_accuracy: 0.4165\n",
            "Epoch 32/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5705 - accuracy: 0.4222 - val_loss: 1.5436 - val_accuracy: 0.4404\n",
            "Epoch 33/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.5631 - accuracy: 0.4263 - val_loss: 1.5868 - val_accuracy: 0.4265\n",
            "Epoch 34/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5597 - accuracy: 0.4288 - val_loss: 1.4919 - val_accuracy: 0.4562\n",
            "Epoch 35/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5497 - accuracy: 0.4298 - val_loss: 1.4799 - val_accuracy: 0.4613\n",
            "Epoch 36/200\n",
            "196/196 [==============================] - 21s 110ms/step - loss: 1.5424 - accuracy: 0.4304 - val_loss: 1.4871 - val_accuracy: 0.4624\n",
            "Epoch 37/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5365 - accuracy: 0.4364 - val_loss: 1.4891 - val_accuracy: 0.4617\n",
            "Epoch 38/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.5296 - accuracy: 0.4386 - val_loss: 1.5197 - val_accuracy: 0.4546\n",
            "Epoch 39/200\n",
            "196/196 [==============================] - 22s 110ms/step - loss: 1.5218 - accuracy: 0.4432 - val_loss: 1.5059 - val_accuracy: 0.4546\n",
            "Epoch 40/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.5202 - accuracy: 0.4408 - val_loss: 1.4677 - val_accuracy: 0.4728\n",
            "Epoch 41/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.5102 - accuracy: 0.4460 - val_loss: 1.4271 - val_accuracy: 0.4869\n",
            "Epoch 42/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.5029 - accuracy: 0.4488 - val_loss: 1.4424 - val_accuracy: 0.4851\n",
            "Epoch 43/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.4978 - accuracy: 0.4504 - val_loss: 1.4191 - val_accuracy: 0.4881\n",
            "Epoch 44/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.4918 - accuracy: 0.4535 - val_loss: 1.5846 - val_accuracy: 0.4359\n",
            "Epoch 45/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.4851 - accuracy: 0.4554 - val_loss: 1.4092 - val_accuracy: 0.4947\n",
            "Epoch 46/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.4813 - accuracy: 0.4567 - val_loss: 1.4095 - val_accuracy: 0.4893\n",
            "Epoch 47/200\n",
            "196/196 [==============================] - 22s 111ms/step - loss: 1.4789 - accuracy: 0.4616 - val_loss: 1.4030 - val_accuracy: 0.4986\n",
            "Epoch 48/200\n",
            " 63/196 [========>.....................] - ETA: 13s - loss: 1.4703 - accuracy: 0.4622"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d5tOmQLvskH",
        "outputId": "f9093898-1ca9-4afd-d670-f448e494c854"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}