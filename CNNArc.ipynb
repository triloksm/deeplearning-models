{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNArc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/triloksm/deeplearning-models/blob/master/CNNArc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline model with dropout on the cifar10 dataset\n",
        "import sys \n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = tensorflow.keras.utils.to_categorical(trainY)\n",
        "\ttestY = tensorflow.keras.utils.to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=1)\n",
        "\n",
        "\t# fit model\n",
        "\t#history = model.fit(trainX, trainY, epochs=200, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaojeKSiHlyZ",
        "outputId": "98976cbd-fb78-4eec-a56a-49bbf42f2b3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 2.1255 - accuracy: 0.2061 - val_loss: 1.9017 - val_accuracy: 0.3343\n",
            "Epoch 2/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.8550 - accuracy: 0.3222 - val_loss: 1.7074 - val_accuracy: 0.3932\n",
            "Epoch 3/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.7162 - accuracy: 0.3684 - val_loss: 1.6796 - val_accuracy: 0.3811\n",
            "Epoch 4/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.6399 - accuracy: 0.3955 - val_loss: 1.5431 - val_accuracy: 0.4392\n",
            "Epoch 5/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.5819 - accuracy: 0.4157 - val_loss: 1.5214 - val_accuracy: 0.4459\n",
            "Epoch 6/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.5323 - accuracy: 0.4377 - val_loss: 1.4470 - val_accuracy: 0.4717\n",
            "Epoch 7/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4882 - accuracy: 0.4579 - val_loss: 1.3925 - val_accuracy: 0.4986\n",
            "Epoch 8/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4493 - accuracy: 0.4691 - val_loss: 1.3605 - val_accuracy: 0.5087\n",
            "Epoch 9/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4154 - accuracy: 0.4861 - val_loss: 1.3548 - val_accuracy: 0.5119\n",
            "Epoch 10/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3805 - accuracy: 0.5016 - val_loss: 1.3337 - val_accuracy: 0.5198\n",
            "Epoch 11/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3514 - accuracy: 0.5140 - val_loss: 1.2898 - val_accuracy: 0.5392\n",
            "Epoch 12/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3178 - accuracy: 0.5245 - val_loss: 1.3141 - val_accuracy: 0.5288\n",
            "Epoch 13/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2908 - accuracy: 0.5348 - val_loss: 1.2123 - val_accuracy: 0.5672\n",
            "Epoch 14/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2605 - accuracy: 0.5484 - val_loss: 1.2105 - val_accuracy: 0.5702\n",
            "Epoch 15/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2375 - accuracy: 0.5553 - val_loss: 1.1527 - val_accuracy: 0.5942\n",
            "Epoch 16/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2077 - accuracy: 0.5670 - val_loss: 1.1800 - val_accuracy: 0.5786\n",
            "Epoch 17/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1841 - accuracy: 0.5773 - val_loss: 1.1238 - val_accuracy: 0.6046\n",
            "Epoch 18/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1619 - accuracy: 0.5867 - val_loss: 1.0786 - val_accuracy: 0.6211\n",
            "Epoch 19/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1402 - accuracy: 0.5954 - val_loss: 1.0488 - val_accuracy: 0.6336\n",
            "Epoch 20/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1179 - accuracy: 0.6011 - val_loss: 1.1580 - val_accuracy: 0.5819\n",
            "Epoch 21/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0982 - accuracy: 0.6111 - val_loss: 1.0656 - val_accuracy: 0.6170\n",
            "Epoch 22/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0783 - accuracy: 0.6190 - val_loss: 0.9946 - val_accuracy: 0.6501\n",
            "Epoch 23/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0599 - accuracy: 0.6252 - val_loss: 1.0147 - val_accuracy: 0.6400\n",
            "Epoch 24/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0417 - accuracy: 0.6300 - val_loss: 1.0308 - val_accuracy: 0.6413\n",
            "Epoch 25/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0257 - accuracy: 0.6366 - val_loss: 0.9888 - val_accuracy: 0.6524\n",
            "Epoch 26/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0090 - accuracy: 0.6427 - val_loss: 0.9731 - val_accuracy: 0.6550\n",
            "Epoch 27/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9945 - accuracy: 0.6482 - val_loss: 0.9166 - val_accuracy: 0.6777\n",
            "Epoch 28/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9767 - accuracy: 0.6560 - val_loss: 0.9127 - val_accuracy: 0.6775\n",
            "Epoch 29/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9625 - accuracy: 0.6600 - val_loss: 0.9238 - val_accuracy: 0.6752\n",
            "Epoch 30/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9460 - accuracy: 0.6653 - val_loss: 0.8815 - val_accuracy: 0.6952\n",
            "Epoch 31/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.9355 - accuracy: 0.6684 - val_loss: 0.8837 - val_accuracy: 0.6913\n",
            "Epoch 32/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9226 - accuracy: 0.6743 - val_loss: 0.8623 - val_accuracy: 0.7012\n",
            "Epoch 33/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9116 - accuracy: 0.6786 - val_loss: 0.8841 - val_accuracy: 0.6927\n",
            "Epoch 34/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8948 - accuracy: 0.6862 - val_loss: 0.8508 - val_accuracy: 0.7030\n",
            "Epoch 35/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8846 - accuracy: 0.6861 - val_loss: 0.8490 - val_accuracy: 0.7029\n",
            "Epoch 36/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8709 - accuracy: 0.6933 - val_loss: 0.8199 - val_accuracy: 0.7146\n",
            "Epoch 37/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8596 - accuracy: 0.6968 - val_loss: 0.8284 - val_accuracy: 0.7121\n",
            "Epoch 38/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8485 - accuracy: 0.7008 - val_loss: 0.8264 - val_accuracy: 0.7092\n",
            "Epoch 39/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8395 - accuracy: 0.7049 - val_loss: 0.7984 - val_accuracy: 0.7239\n",
            "Epoch 40/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8245 - accuracy: 0.7117 - val_loss: 0.8190 - val_accuracy: 0.7149\n",
            "Epoch 41/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8207 - accuracy: 0.7123 - val_loss: 0.7973 - val_accuracy: 0.7199\n",
            "Epoch 42/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8081 - accuracy: 0.7167 - val_loss: 0.7630 - val_accuracy: 0.7364\n",
            "Epoch 43/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7961 - accuracy: 0.7193 - val_loss: 0.7743 - val_accuracy: 0.7281\n",
            "Epoch 44/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7892 - accuracy: 0.7212 - val_loss: 0.8290 - val_accuracy: 0.7062\n",
            "Epoch 45/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7774 - accuracy: 0.7274 - val_loss: 0.7656 - val_accuracy: 0.7345\n",
            "Epoch 46/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7686 - accuracy: 0.7309 - val_loss: 0.7643 - val_accuracy: 0.7308\n",
            "Epoch 47/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7578 - accuracy: 0.7353 - val_loss: 0.7278 - val_accuracy: 0.7514\n",
            "Epoch 48/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7515 - accuracy: 0.7345 - val_loss: 0.7418 - val_accuracy: 0.7433\n",
            "Epoch 49/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7441 - accuracy: 0.7377 - val_loss: 0.7144 - val_accuracy: 0.7515\n",
            "Epoch 50/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7328 - accuracy: 0.7421 - val_loss: 0.7420 - val_accuracy: 0.7400\n",
            "Epoch 51/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7274 - accuracy: 0.7441 - val_loss: 0.7212 - val_accuracy: 0.7473\n",
            "Epoch 52/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7211 - accuracy: 0.7464 - val_loss: 0.7243 - val_accuracy: 0.7464\n",
            "Epoch 53/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7121 - accuracy: 0.7505 - val_loss: 0.7259 - val_accuracy: 0.7518\n",
            "Epoch 54/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.7065 - accuracy: 0.7532 - val_loss: 0.6979 - val_accuracy: 0.7575\n",
            "Epoch 55/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6982 - accuracy: 0.7550 - val_loss: 0.7158 - val_accuracy: 0.7503\n",
            "Epoch 56/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6919 - accuracy: 0.7561 - val_loss: 0.7191 - val_accuracy: 0.7494\n",
            "Epoch 57/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6857 - accuracy: 0.7576 - val_loss: 0.6953 - val_accuracy: 0.7578\n",
            "Epoch 58/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6766 - accuracy: 0.7634 - val_loss: 0.7007 - val_accuracy: 0.7560\n",
            "Epoch 59/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6717 - accuracy: 0.7639 - val_loss: 0.6795 - val_accuracy: 0.7653\n",
            "Epoch 60/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6655 - accuracy: 0.7653 - val_loss: 0.6656 - val_accuracy: 0.7671\n",
            "Epoch 61/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6550 - accuracy: 0.7689 - val_loss: 0.6719 - val_accuracy: 0.7677\n",
            "Epoch 62/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6522 - accuracy: 0.7712 - val_loss: 0.6623 - val_accuracy: 0.7681\n",
            "Epoch 63/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6498 - accuracy: 0.7730 - val_loss: 0.6564 - val_accuracy: 0.7693\n",
            "Epoch 64/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6361 - accuracy: 0.7755 - val_loss: 0.6542 - val_accuracy: 0.7742\n",
            "Epoch 65/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.6322 - accuracy: 0.7760 - val_loss: 0.6540 - val_accuracy: 0.7739\n",
            "Epoch 66/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6261 - accuracy: 0.7787 - val_loss: 0.6397 - val_accuracy: 0.7763\n",
            "Epoch 67/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6218 - accuracy: 0.7817 - val_loss: 0.6398 - val_accuracy: 0.7746\n",
            "Epoch 68/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6142 - accuracy: 0.7844 - val_loss: 0.6520 - val_accuracy: 0.7754\n",
            "Epoch 69/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6144 - accuracy: 0.7847 - val_loss: 0.6566 - val_accuracy: 0.7729\n",
            "Epoch 70/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6014 - accuracy: 0.7884 - val_loss: 0.6368 - val_accuracy: 0.7777\n",
            "Epoch 71/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6006 - accuracy: 0.7878 - val_loss: 0.6341 - val_accuracy: 0.7797\n",
            "Epoch 72/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5940 - accuracy: 0.7913 - val_loss: 0.6290 - val_accuracy: 0.7817\n",
            "Epoch 73/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5888 - accuracy: 0.7939 - val_loss: 0.6379 - val_accuracy: 0.7783\n",
            "Epoch 74/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5840 - accuracy: 0.7952 - val_loss: 0.6447 - val_accuracy: 0.7753\n",
            "Epoch 75/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5798 - accuracy: 0.7975 - val_loss: 0.6061 - val_accuracy: 0.7884\n",
            "Epoch 76/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5713 - accuracy: 0.7978 - val_loss: 0.6289 - val_accuracy: 0.7817\n",
            "Epoch 77/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5708 - accuracy: 0.7996 - val_loss: 0.6130 - val_accuracy: 0.7875\n",
            "Epoch 78/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5624 - accuracy: 0.8029 - val_loss: 0.6056 - val_accuracy: 0.7876\n",
            "Epoch 79/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5630 - accuracy: 0.8013 - val_loss: 0.6115 - val_accuracy: 0.7882\n",
            "Epoch 80/200\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 0.5536 - accuracy: 0.8030 - val_loss: 0.5993 - val_accuracy: 0.7938\n",
            "Epoch 81/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5495 - accuracy: 0.8059 - val_loss: 0.5986 - val_accuracy: 0.7935\n",
            "Epoch 82/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5457 - accuracy: 0.8075 - val_loss: 0.6009 - val_accuracy: 0.7930\n",
            "Epoch 83/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5410 - accuracy: 0.8095 - val_loss: 0.5951 - val_accuracy: 0.7940\n",
            "Epoch 84/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5386 - accuracy: 0.8108 - val_loss: 0.6055 - val_accuracy: 0.7892\n",
            "Epoch 85/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5295 - accuracy: 0.8133 - val_loss: 0.6079 - val_accuracy: 0.7892\n",
            "Epoch 86/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5259 - accuracy: 0.8142 - val_loss: 0.5899 - val_accuracy: 0.7950\n",
            "Epoch 87/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5238 - accuracy: 0.8149 - val_loss: 0.5960 - val_accuracy: 0.7911\n",
            "Epoch 88/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5204 - accuracy: 0.8172 - val_loss: 0.6145 - val_accuracy: 0.7875\n",
            "Epoch 89/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5136 - accuracy: 0.8189 - val_loss: 0.5907 - val_accuracy: 0.7944\n",
            "Epoch 90/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5100 - accuracy: 0.8213 - val_loss: 0.5881 - val_accuracy: 0.7958\n",
            "Epoch 91/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5035 - accuracy: 0.8212 - val_loss: 0.5847 - val_accuracy: 0.7966\n",
            "Epoch 92/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.5008 - accuracy: 0.8226 - val_loss: 0.5754 - val_accuracy: 0.8001\n",
            "Epoch 93/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4955 - accuracy: 0.8258 - val_loss: 0.5856 - val_accuracy: 0.7965\n",
            "Epoch 94/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4976 - accuracy: 0.8255 - val_loss: 0.5823 - val_accuracy: 0.7999\n",
            "Epoch 95/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4864 - accuracy: 0.8295 - val_loss: 0.5758 - val_accuracy: 0.8030\n",
            "Epoch 96/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4808 - accuracy: 0.8297 - val_loss: 0.5688 - val_accuracy: 0.8034\n",
            "Epoch 97/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4761 - accuracy: 0.8318 - val_loss: 0.5718 - val_accuracy: 0.8010\n",
            "Epoch 98/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4770 - accuracy: 0.8314 - val_loss: 0.5625 - val_accuracy: 0.8061\n",
            "Epoch 99/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4680 - accuracy: 0.8356 - val_loss: 0.5813 - val_accuracy: 0.8007\n",
            "Epoch 100/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4681 - accuracy: 0.8360 - val_loss: 0.5861 - val_accuracy: 0.7991\n",
            "Epoch 101/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4631 - accuracy: 0.8366 - val_loss: 0.5586 - val_accuracy: 0.8076\n",
            "Epoch 102/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4580 - accuracy: 0.8371 - val_loss: 0.5856 - val_accuracy: 0.8020\n",
            "Epoch 103/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4540 - accuracy: 0.8392 - val_loss: 0.5823 - val_accuracy: 0.8018\n",
            "Epoch 104/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4500 - accuracy: 0.8415 - val_loss: 0.5762 - val_accuracy: 0.8030\n",
            "Epoch 105/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4465 - accuracy: 0.8426 - val_loss: 0.5682 - val_accuracy: 0.8085\n",
            "Epoch 106/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4434 - accuracy: 0.8433 - val_loss: 0.5834 - val_accuracy: 0.8025\n",
            "Epoch 107/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4413 - accuracy: 0.8447 - val_loss: 0.5545 - val_accuracy: 0.8145\n",
            "Epoch 108/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4388 - accuracy: 0.8444 - val_loss: 0.5589 - val_accuracy: 0.8082\n",
            "Epoch 109/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4271 - accuracy: 0.8485 - val_loss: 0.5522 - val_accuracy: 0.8117\n",
            "Epoch 110/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4283 - accuracy: 0.8469 - val_loss: 0.5541 - val_accuracy: 0.8122\n",
            "Epoch 111/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4222 - accuracy: 0.8513 - val_loss: 0.5664 - val_accuracy: 0.8080\n",
            "Epoch 112/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4174 - accuracy: 0.8523 - val_loss: 0.5592 - val_accuracy: 0.8102\n",
            "Epoch 113/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4194 - accuracy: 0.8508 - val_loss: 0.5779 - val_accuracy: 0.8053\n",
            "Epoch 114/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.4154 - accuracy: 0.8506 - val_loss: 0.5484 - val_accuracy: 0.8151\n",
            "Epoch 115/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4096 - accuracy: 0.8549 - val_loss: 0.5694 - val_accuracy: 0.8101\n",
            "Epoch 116/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4050 - accuracy: 0.8559 - val_loss: 0.5551 - val_accuracy: 0.8116\n",
            "Epoch 117/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4004 - accuracy: 0.8585 - val_loss: 0.5636 - val_accuracy: 0.8066\n",
            "Epoch 118/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4021 - accuracy: 0.8561 - val_loss: 0.5695 - val_accuracy: 0.8097\n",
            "Epoch 119/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3970 - accuracy: 0.8580 - val_loss: 0.5512 - val_accuracy: 0.8153\n",
            "Epoch 120/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3945 - accuracy: 0.8596 - val_loss: 0.5645 - val_accuracy: 0.8113\n",
            "Epoch 121/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3903 - accuracy: 0.8621 - val_loss: 0.5519 - val_accuracy: 0.8146\n",
            "Epoch 122/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3823 - accuracy: 0.8649 - val_loss: 0.5521 - val_accuracy: 0.8154\n",
            "Epoch 123/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3851 - accuracy: 0.8628 - val_loss: 0.5475 - val_accuracy: 0.8156\n",
            "Epoch 124/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3790 - accuracy: 0.8661 - val_loss: 0.5475 - val_accuracy: 0.8159\n",
            "Epoch 125/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3772 - accuracy: 0.8653 - val_loss: 0.5547 - val_accuracy: 0.8149\n",
            "Epoch 126/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3764 - accuracy: 0.8647 - val_loss: 0.5404 - val_accuracy: 0.8184\n",
            "Epoch 127/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3692 - accuracy: 0.8700 - val_loss: 0.5547 - val_accuracy: 0.8157\n",
            "Epoch 128/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3646 - accuracy: 0.8689 - val_loss: 0.5382 - val_accuracy: 0.8219\n",
            "Epoch 129/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3643 - accuracy: 0.8701 - val_loss: 0.5490 - val_accuracy: 0.8176\n",
            "Epoch 130/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3586 - accuracy: 0.8715 - val_loss: 0.5546 - val_accuracy: 0.8175\n",
            "Epoch 131/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3553 - accuracy: 0.8734 - val_loss: 0.5495 - val_accuracy: 0.8170\n",
            "Epoch 132/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3579 - accuracy: 0.8722 - val_loss: 0.5380 - val_accuracy: 0.8214\n",
            "Epoch 133/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3540 - accuracy: 0.8742 - val_loss: 0.5421 - val_accuracy: 0.8177\n",
            "Epoch 134/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3485 - accuracy: 0.8755 - val_loss: 0.5390 - val_accuracy: 0.8218\n",
            "Epoch 135/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3477 - accuracy: 0.8749 - val_loss: 0.5635 - val_accuracy: 0.8141\n",
            "Epoch 136/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3406 - accuracy: 0.8790 - val_loss: 0.5439 - val_accuracy: 0.8206\n",
            "Epoch 137/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3397 - accuracy: 0.8780 - val_loss: 0.5378 - val_accuracy: 0.8211\n",
            "Epoch 138/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3378 - accuracy: 0.8812 - val_loss: 0.5449 - val_accuracy: 0.8198\n",
            "Epoch 139/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3336 - accuracy: 0.8806 - val_loss: 0.5318 - val_accuracy: 0.8253\n",
            "Epoch 140/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3256 - accuracy: 0.8826 - val_loss: 0.5407 - val_accuracy: 0.8204\n",
            "Epoch 141/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3261 - accuracy: 0.8833 - val_loss: 0.5635 - val_accuracy: 0.8182\n",
            "Epoch 142/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3230 - accuracy: 0.8849 - val_loss: 0.5546 - val_accuracy: 0.8209\n",
            "Epoch 143/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3174 - accuracy: 0.8852 - val_loss: 0.5495 - val_accuracy: 0.8228\n",
            "Epoch 144/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3177 - accuracy: 0.8875 - val_loss: 0.5512 - val_accuracy: 0.8229\n",
            "Epoch 145/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3161 - accuracy: 0.8861 - val_loss: 0.5606 - val_accuracy: 0.8187\n",
            "Epoch 146/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.3093 - accuracy: 0.8897 - val_loss: 0.5558 - val_accuracy: 0.8203\n",
            "Epoch 147/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3087 - accuracy: 0.8893 - val_loss: 0.5485 - val_accuracy: 0.8215\n",
            "Epoch 148/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3083 - accuracy: 0.8912 - val_loss: 0.5440 - val_accuracy: 0.8245\n",
            "Epoch 149/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3022 - accuracy: 0.8897 - val_loss: 0.5460 - val_accuracy: 0.8233\n",
            "Epoch 150/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2961 - accuracy: 0.8949 - val_loss: 0.5542 - val_accuracy: 0.8212\n",
            "Epoch 151/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2982 - accuracy: 0.8929 - val_loss: 0.5383 - val_accuracy: 0.8223\n",
            "Epoch 152/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2964 - accuracy: 0.8939 - val_loss: 0.5468 - val_accuracy: 0.8252\n",
            "Epoch 153/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2916 - accuracy: 0.8950 - val_loss: 0.5634 - val_accuracy: 0.8199\n",
            "Epoch 154/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2885 - accuracy: 0.8962 - val_loss: 0.5446 - val_accuracy: 0.8249\n",
            "Epoch 155/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2835 - accuracy: 0.8984 - val_loss: 0.5538 - val_accuracy: 0.8230\n",
            "Epoch 156/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2865 - accuracy: 0.8974 - val_loss: 0.5525 - val_accuracy: 0.8272\n",
            "Epoch 157/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2824 - accuracy: 0.8992 - val_loss: 0.5586 - val_accuracy: 0.8241\n",
            "Epoch 158/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2752 - accuracy: 0.9003 - val_loss: 0.5504 - val_accuracy: 0.8266\n",
            "Epoch 159/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2772 - accuracy: 0.9004 - val_loss: 0.5527 - val_accuracy: 0.8259\n",
            "Epoch 160/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2704 - accuracy: 0.9041 - val_loss: 0.5401 - val_accuracy: 0.8274\n",
            "Epoch 161/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2671 - accuracy: 0.9042 - val_loss: 0.5681 - val_accuracy: 0.8225\n",
            "Epoch 162/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2641 - accuracy: 0.9044 - val_loss: 0.5874 - val_accuracy: 0.8172\n",
            "Epoch 163/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2639 - accuracy: 0.9035 - val_loss: 0.5543 - val_accuracy: 0.8272\n",
            "Epoch 164/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.5511 - val_accuracy: 0.8259\n",
            "Epoch 165/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2582 - accuracy: 0.9074 - val_loss: 0.5623 - val_accuracy: 0.8262\n",
            "Epoch 166/200\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 0.2558 - accuracy: 0.9085 - val_loss: 0.5529 - val_accuracy: 0.8314\n",
            "Epoch 167/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2563 - accuracy: 0.9071 - val_loss: 0.5759 - val_accuracy: 0.8252\n",
            "Epoch 168/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2512 - accuracy: 0.9091 - val_loss: 0.5550 - val_accuracy: 0.8258\n",
            "Epoch 169/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2485 - accuracy: 0.9105 - val_loss: 0.5586 - val_accuracy: 0.8255\n",
            "Epoch 170/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2463 - accuracy: 0.9116 - val_loss: 0.5592 - val_accuracy: 0.8288\n",
            "Epoch 171/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2422 - accuracy: 0.9115 - val_loss: 0.5588 - val_accuracy: 0.8267\n",
            "Epoch 172/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2428 - accuracy: 0.9125 - val_loss: 0.5663 - val_accuracy: 0.8254\n",
            "Epoch 173/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2400 - accuracy: 0.9132 - val_loss: 0.5594 - val_accuracy: 0.8279\n",
            "Epoch 174/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2386 - accuracy: 0.9139 - val_loss: 0.5662 - val_accuracy: 0.8296\n",
            "Epoch 175/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2369 - accuracy: 0.9149 - val_loss: 0.5670 - val_accuracy: 0.8277\n",
            "Epoch 176/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2344 - accuracy: 0.9150 - val_loss: 0.5850 - val_accuracy: 0.8231\n",
            "Epoch 177/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2279 - accuracy: 0.9185 - val_loss: 0.5821 - val_accuracy: 0.8286\n",
            "Epoch 178/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2295 - accuracy: 0.9170 - val_loss: 0.5663 - val_accuracy: 0.8269\n",
            "Epoch 179/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2285 - accuracy: 0.9171 - val_loss: 0.5657 - val_accuracy: 0.8298\n",
            "Epoch 180/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2248 - accuracy: 0.9189 - val_loss: 0.5543 - val_accuracy: 0.8291\n",
            "Epoch 181/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2202 - accuracy: 0.9204 - val_loss: 0.5654 - val_accuracy: 0.8277\n",
            "Epoch 182/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2216 - accuracy: 0.9198 - val_loss: 0.5653 - val_accuracy: 0.8285\n",
            "Epoch 183/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2172 - accuracy: 0.9224 - val_loss: 0.5661 - val_accuracy: 0.8291\n",
            "Epoch 184/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2147 - accuracy: 0.9232 - val_loss: 0.5670 - val_accuracy: 0.8293\n",
            "Epoch 185/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2166 - accuracy: 0.9225 - val_loss: 0.5644 - val_accuracy: 0.8305\n",
            "Epoch 186/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2125 - accuracy: 0.9226 - val_loss: 0.5632 - val_accuracy: 0.8314\n",
            "Epoch 187/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2082 - accuracy: 0.9242 - val_loss: 0.5700 - val_accuracy: 0.8285\n",
            "Epoch 188/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2111 - accuracy: 0.9241 - val_loss: 0.5689 - val_accuracy: 0.8288\n",
            "Epoch 189/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2061 - accuracy: 0.9257 - val_loss: 0.5782 - val_accuracy: 0.8283\n",
            "Epoch 190/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2014 - accuracy: 0.9287 - val_loss: 0.5721 - val_accuracy: 0.8306\n",
            "Epoch 191/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2020 - accuracy: 0.9285 - val_loss: 0.5668 - val_accuracy: 0.8293\n",
            "Epoch 192/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.2001 - accuracy: 0.9267 - val_loss: 0.5799 - val_accuracy: 0.8286\n",
            "Epoch 193/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1986 - accuracy: 0.9285 - val_loss: 0.5886 - val_accuracy: 0.8245\n",
            "Epoch 194/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1940 - accuracy: 0.9304 - val_loss: 0.5718 - val_accuracy: 0.8301\n",
            "Epoch 195/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1915 - accuracy: 0.9319 - val_loss: 0.5784 - val_accuracy: 0.8322\n",
            "Epoch 196/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1927 - accuracy: 0.9321 - val_loss: 0.5810 - val_accuracy: 0.8291\n",
            "Epoch 197/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1924 - accuracy: 0.9306 - val_loss: 0.5755 - val_accuracy: 0.8303\n",
            "Epoch 198/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1901 - accuracy: 0.9317 - val_loss: 0.5833 - val_accuracy: 0.8311\n",
            "Epoch 199/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1869 - accuracy: 0.9320 - val_loss: 0.5863 - val_accuracy: 0.8299\n",
            "Epoch 200/200\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.1883 - accuracy: 0.9326 - val_loss: 0.5759 - val_accuracy: 0.8315\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5759 - accuracy: 0.8315\n",
            "> 83.150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "snlgqIDO65Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d5tOmQLvskH",
        "outputId": "f9093898-1ca9-4afd-d670-f448e494c854"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}